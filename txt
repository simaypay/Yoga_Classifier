Some challenges we have encountered:
Our model uses media pipe pose for detecting the landmarks our our body. However, the output we retained from the media pipe library are coordinates (x,y,z,vis) Training the model with the coordinates of the landmarks could have created issues with the scaling and the centering. We had to take into account that each user would have different length of limbs , torsos, etc. we would also have to center the coordinates in order to classify each pose. Moreover in our feedback system, we want to show how well a user is doing by adding an indicator on each joint.  We decided to use classification not by coordinates , but angles between landmarks, aka joints. This way scaling was not an issue. we have decided on 14 important joints and calculated the angles for each using another function that calculates the angle between 3 landmarks using their x and y coordinates. model easily classifies each pose from their distinct angles. And feedback system ....(better )

Some of the poses in yoga are not symmetrical. Although our model could classify the pose because ..(technical stuff ask gpt) .. we encountered an issue with our feedback system.  let's take an example from the "tree " pose. We could not give feedback on exactly which leg to lift because our feedback system works with hardcoded ideal angles for each pose we are considering.
We were either going to add conditions to our feedback system or change the training. Since we had already made our own csv files for training from dataset, all we needed to do was find a new dataset for separate labels for right and lefts, and retrain our model.